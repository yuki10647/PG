{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/pocokhc/items/f20b1518fb36f4ad0d00\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_train = pd.read_csv('TrainOfTitanic.csv') #os.path.join調べてみる\n",
    "df_test = pd.read_csv('TestOfTitaic.csv')\n",
    "target_column = \"Survived\"  # 目的変数\n",
    "random_seed = 1234   # 乱数固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 総データ数\n",
    "print(len(df_train))\n",
    "print(len(df_test))\n",
    "# 欠損値の数を表示\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fareのデータを見る例(今回Fareは欠損一つなので、見て補う)\n",
    "print(df_test[df_test[\"Fare\"].isnull()].T)\n",
    "# .Tは記事として見やすいように転置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarkedの欠損をみる(2件)\n",
    "print(df_train[df_train[\"Embarked\"].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要約情報\n",
    "print(df_train.describe(include='all'))\n",
    "print(df_test.describe(include='all'))\n",
    "#確認ポイント\n",
    "#(数字データ)外れ値がないか(meanに対するminとmaxらへんを確認)\n",
    "#(数字データ)データの散らばり具合(meanに対する50%(中央値)がどれだけ離れているか)\n",
    "#(文字データ)カテゴリデータかどうか(countとuniqueの数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e667fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_train.columns:\n",
    "    # uniq情報を取得\n",
    "    uniq = df_train[column].unique()\n",
    "    # 表示                                                  # 多すぎる場合があるので5件に抑える\n",
    "    print(\"{:20} unique:{:5} {}\".format(column, len(uniq), uniq[:5])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ad63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Survived\n",
    "print(df_train['Survived'].value_counts())  # 数\n",
    "print(df_train['Survived'].value_counts(normalize=True))  # 割合\n",
    "sns.countplot(x=\"Survived\", data=df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eda0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category(df, column, target_column):\n",
    "    \n",
    "    print(pd.crosstab(df[column],df[target_column]))\n",
    "    print(\"各クラス毎の生存率\")\n",
    "    print(pd.crosstab(df[column],df[target_column], normalize='index'))\n",
    "    print(\"生存率に対する各クラスの割合\")\n",
    "    print(pd.crosstab(df[column],df[target_column], normalize='columns'))\n",
    "    sns.countplot(df[column], hue=df[target_column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category(df_train, 'Pclass', target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b2cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category(df_train, 'Sex', target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4875ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category(df_train, 'SibSp', target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95828259",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category(df_train, 'Parch', target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed553f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category(df_train, 'Embarked', target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_float(df, column, target_column, bins=20):\n",
    "    # 全体plot\n",
    "    sns.distplot(df[column], kde=True, rug=False, bins=bins)\n",
    "    plt.show()\n",
    "    # 目的変数毎のplot\n",
    "    sns.distplot(df[df[target_column]==1][column], kde=True, rug=False, bins=bins, label=1)\n",
    "    sns.distplot(df[df[target_column]==0][column], kde=True, rug=False, bins=bins, label=0)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_float(df_train, \"Age\", \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_float(df_train, \"Fare\", \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "\n",
    "def missing_value(df):\n",
    "    # 欠損値フラグ\n",
    "    df[\"Age_na\"] = df[\"Age\"].isnull().astype(np.int64)\n",
    "    # 欠損値を中央値で埋める\n",
    "    df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
    "\n",
    "missing_value(df_train) \n",
    "missing_value(df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c310eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked\n",
    "df_train[\"Embarked\"].fillna(\"S\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare\n",
    "df_test[\"Fare\"].fillna(df_test['Fare'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49542006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化(不偏分散)\n",
    "\n",
    "def normalization(df, name):\n",
    "    df[name] = (df[name] - df[name].mean()) / df[name].std()\n",
    "\n",
    "#normalization(df_train, \"Age\")\n",
    "#normalization(df_train, \"Fare\")\n",
    "#normalization(df_test, \"Age\")\n",
    "#normalization(df_test, \"Fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca52581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダミー化\n",
    "\n",
    "def dummy(df):\n",
    "    df = pd.get_dummies(df, columns=[\n",
    "        \"Pclass\", \n",
    "        \"Sex\", \n",
    "        #\"SibSp\",\n",
    "        #\"Parch\",\n",
    "        \"Embarked\",\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "df_train = dummy(df_train)\n",
    "df_test = dummy(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数\n",
    "print(list(df_train.columns))\n",
    "\n",
    "select_columns = [\n",
    "    \"Age\",\n",
    "    \"Age_na\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\", \n",
    "    \"Pclass_1\",\n",
    "    \"Pclass_2\",\n",
    "    #\"Pclass_3\",  # dummy除外\n",
    "    \"Sex_male\",\n",
    "    #\"Sex_female\",  # dummy除外\n",
    "    \"Embarked_C\",\n",
    "    \"Embarked_Q\",\n",
    "    #\"Embarked_S\",  # dummy除外\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "import sklearn.gaussian_process\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "import sklearn.tree\n",
    "import sklearn.discriminant_analysis\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca04087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(random_seed):\n",
    "    models = [\n",
    "        #Ensemble Methods\n",
    "        sklearn.ensemble.AdaBoostClassifier(random_state=random_seed),\n",
    "        sklearn.ensemble.BaggingClassifier(random_state=random_seed),\n",
    "        sklearn.ensemble.ExtraTreesClassifier(random_state=random_seed),\n",
    "        sklearn.ensemble.GradientBoostingClassifier(random_state=random_seed),\n",
    "        sklearn.ensemble.RandomForestClassifier(random_state=random_seed),\n",
    "\n",
    "        #Gaussian Processes\n",
    "        sklearn.gaussian_process.GaussianProcessClassifier(random_state=random_seed),\n",
    "\n",
    "        #GLM\n",
    "        sklearn.linear_model.LogisticRegressionCV(random_state=random_seed),\n",
    "        sklearn.linear_model.RidgeClassifierCV(),\n",
    "        \n",
    "        #Navies Bayes\n",
    "        sklearn.naive_bayes.BernoulliNB(),\n",
    "        sklearn.naive_bayes.GaussianNB(),\n",
    "\n",
    "        #Nearest Neighbor\n",
    "        sklearn.neighbors.KNeighborsClassifier(),\n",
    "\n",
    "        #Trees\n",
    "        sklearn.tree.DecisionTreeClassifier(random_state=random_seed),\n",
    "        sklearn.tree.ExtraTreeClassifier(random_state=random_seed),\n",
    "\n",
    "        #Discriminant Analysis\n",
    "        sklearn.discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "        sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "        #xgboost\n",
    "        xgb.XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, random_state=random_seed),\n",
    "\n",
    "        # light bgm\n",
    "        lgb.LGBMClassifier(random_state=random_seed),\n",
    "    ]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(df, columns, target_column, random_seed):\n",
    "    # 教師データを作成\n",
    "    x = df[columns].to_numpy()\n",
    "    y = df[target_column].to_numpy()\n",
    "\n",
    "    # 交叉検証\n",
    "    model_scores = {}\n",
    "    kf = sklearn.model_selection.KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "    for train_idx, true_idx in kf.split(x, y):\n",
    "        # 各学習データとテストデータ\n",
    "        x_train = x[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        x_true = x[true_idx]\n",
    "        y_true = y[true_idx]\n",
    "\n",
    "        # 各モデル毎に学習\n",
    "        for model in create_models(random_seed):\n",
    "            name = model.__class__.__name__\n",
    "            if name not in model_scores:\n",
    "                model_scores[name] = []\n",
    "            \n",
    "            # モデルの学習と評価\n",
    "            model.fit(x_train, y_train)\n",
    "            pred_y = model.predict(x_true)\n",
    "\n",
    "            # 結果を評価\n",
    "            model_scores[name].append((\n",
    "                sklearn.metrics.accuracy_score(y_true, pred_y),\n",
    "                sklearn.metrics.precision_score(y_true, pred_y),\n",
    "                sklearn.metrics.recall_score(y_true, pred_y),\n",
    "                sklearn.metrics.f1_score(y_true, pred_y),\n",
    "            ))\n",
    "    accs = []\n",
    "    for k, scores in model_scores.items():\n",
    "        scores = np.mean(scores, axis=0)\n",
    "\n",
    "        # モデル毎の平均\n",
    "        print(\"正解率 {:.3f}, 適合率 {:.3f}, 再現率 {:.3f}, F値 {:.3f} : {}\".format(\n",
    "            scores[0],\n",
    "            scores[1],\n",
    "            scores[2],\n",
    "            scores[3],\n",
    "            k,\n",
    "        ))\n",
    "        accs.append(scores)\n",
    "    \n",
    "    # 全モデルの中央値\n",
    "    accs = np.median(accs, axis=0)  # 中央値\n",
    "    print(\"正解率 {:.3f}, 適合率 {:.3f}, 再現率 {:.3f}, F値 {:.3f}\".format(accs[0], accs[1], accs[2], accs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a109f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(df_train, select_columns, target_column, random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc09649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データを作成\n",
    "x = df_train[select_columns].to_numpy()\n",
    "y = df_train[target_column].to_numpy()\n",
    "\n",
    "# 出力用データ\n",
    "x_test = df_test[select_columns].to_numpy()\n",
    "\n",
    "# ランダムフォレストで学習し、評価する\n",
    "model = sklearn.ensemble.RandomForestClassifier(random_state=random_seed)\n",
    "model.fit(x, y)\n",
    "pred_y = model.predict(x_test)\n",
    "\n",
    "# 提出用にデータ加工\n",
    "output = pd.DataFrame({'PassengerId': df_test[\"PassengerId\"], 'Survived': pred_y})\n",
    "output.to_csv(\"result.csv\", header=True, index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e210192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#その他の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数の影響度\n",
    "def print_feature_importance(df, columns, target_column, random_seed):\n",
    "    x = df[columns]\n",
    "    y = df[target_column]\n",
    "\n",
    "    print(\"--- RandomForestClassifier\")\n",
    "    model = sklearn.ensemble.RandomForestClassifier(random_state=random_seed)\n",
    "    model.fit(x, y)\n",
    "    fti1 = model.feature_importances_\n",
    "    for i, column in enumerate(columns):\n",
    "        print('{:20s} : {:>.6f}'.format(column, fti1[i]))\n",
    "\n",
    "    print(\"--- XGBClassifier\")\n",
    "    model = xgb.XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)\n",
    "    model.fit(x, y)\n",
    "    fti2 = model.feature_importances_\n",
    "    for i, column in enumerate(columns):\n",
    "        print('{:20s} : {:>.6f}'.format(column, fti2[i]))\n",
    "\n",
    "\n",
    "    print(\"--- LGBMClassifier\")\n",
    "    model = lgb.LGBMClassifier(random_state=random_seed)\n",
    "    model.fit(x, y)\n",
    "    fti3 = model.feature_importances_   \n",
    "    for i, column in enumerate(columns):\n",
    "        print('{:20s} : {:>.2f}'.format(column, fti3[i]))\n",
    "        \n",
    "        \n",
    "    #--- 結果をplot\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(3, 1, 1, title=\"RandomForestClassifier(Feature Importance)\")\n",
    "    ax2 = fig.add_subplot(3, 1, 2, title=\"XGBClassifier(Feature Importance)\")\n",
    "    ax3 = fig.add_subplot(3, 1, 3, title=\"LGBMClassifier(Feature Importance)\")\n",
    "    ax1.barh(columns, fti1)\n",
    "    ax2.barh(columns, fti2)\n",
    "    ax3.barh(columns, fti3)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "print_feature_importance(df_train, select_columns, target_column, random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#回帰分析\n",
    "\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "def print_statsmodels(df, columns, target_column):\n",
    "    # 重回帰分析\n",
    "    X1_train = sm.add_constant(df[columns])\n",
    "    y = df[target_column]\n",
    "    model = sm.OLS(y, X1_train)\n",
    "    fitted = model.fit()\n",
    "\n",
    "    print(\"--- 重回帰分析の決定係数\")\n",
    "    for i, column in enumerate(columns):\n",
    "        print('\\t{:15s} : {:7.4f}(coef) {:5.1f}%(P>|t|)'.format(\n",
    "            column, \n",
    "            fitted.params[i+1],\n",
    "            fitted.pvalues[i]*100\n",
    "        ))\n",
    "    print(\"\")\n",
    "   \n",
    "　　# 各columnにおけるクック距離をだす\n",
    "    print(\"--- 外れ値(cook_distance threshold:0.5)\")\n",
    "    for column in columns:\n",
    "        # 単回帰分析\n",
    "        X1_train = sm.add_constant(df[column])\n",
    "        model = sm.OLS(y, X1_train)\n",
    "        fitted = model.fit()\n",
    "\n",
    "        cook_distance, p_value = OLSInfluence(fitted).cooks_distance\n",
    "        kouho = np.where(cook_distance > 0.5)[0]\n",
    "        if len(kouho) == 0:\n",
    "            print(\"{:20s} cook_distance is 0(max: {:.4f})\".format(column, np.max(cook_distance)))\n",
    "        else:\n",
    "            for index in kouho:\n",
    "                print(\"{:20s} cook_distance: {}, index: {}\".format(column, cook_distance[index], index))\n",
    "    print(\"\")\n",
    "\n",
    "# 実行\n",
    "print_statsmodels(df_train, select_columns, target_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_correlation(df, columns):\n",
    "\n",
    "    # 相関係数1:1\n",
    "    print(\"--- 相関係数1:1 (threshold: 0.5)\")\n",
    "    cor = df[columns].corr()\n",
    "    count = 0\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(i+1, len(columns)):\n",
    "            val = cor[columns[i]][j]\n",
    "            if abs(val) > 0.5:\n",
    "                print(\"{} {}: {:.2f}\".format(columns[i], columns[j], val))\n",
    "                count += 1\n",
    "    if count == 0:\n",
    "        print(\"empty\")\n",
    "    print(\"\")\n",
    "\n",
    "    # heatmap\n",
    "    plt.figure(figsize=(12,9))\n",
    "    sns.heatmap(df[columns].corr(), annot=True, vmax=1, vmin=-1, fmt='.1f', cmap='RdBu')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # 相関係数1:多\n",
    "    # 5以上だとあやしい、10だとかなり確定\n",
    "    print(\"--- VIF(5以上だと怪しい)\")\n",
    "    vif = pd.DataFrame()\n",
    "    x = df[columns]\n",
    "    vif[\"VIF Factor\"] = [\n",
    "        variance_inflation_factor(x.values, i) for i in range(x.shape[1])\n",
    "    ]\n",
    "    vif[\"features\"] = columns\n",
    "    print(vif)\n",
    "    plt.barh(columns, vif[\"VIF Factor\"])\n",
    "    plt.vlines([5], 0, len(columns), \"blue\", linestyles='dashed')\n",
    "    plt.vlines([10], 0, len(columns), \"red\", linestyles='dashed')\n",
    "    plt.title(\"VIF\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "print_statsmodels(df_train, select_columns, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数同士の相関\n",
    "def print_correlation(df, columns):\n",
    "\n",
    "    # 相関係数1:1\n",
    "    print(\"--- 相関係数1:1 (threshold: 0.5)\")\n",
    "    cor = df[columns].corr()\n",
    "    count = 0\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(i+1, len(columns)):\n",
    "            val = cor[columns[i]][j]\n",
    "            if abs(val) > 0.5:\n",
    "                print(\"{} {}: {:.2f}\".format(columns[i], columns[j], val))\n",
    "                count += 1\n",
    "    if count == 0:\n",
    "        print(\"empty\")\n",
    "    print(\"\")\n",
    "\n",
    "    # heatmap\n",
    "    plt.figure(figsize=(12,9))\n",
    "    sns.heatmap(df[columns].corr(), annot=True, vmax=1, vmin=-1, fmt='.1f', cmap='RdBu')\n",
    "    plt.show()\n",
    "\n",
    "    # 相関係数1:多\n",
    "    # 5以上だとあやしい、10だとかなり確定\n",
    "    print(\"--- VIF(5以上だと怪しい)\")\n",
    "    vif = pd.DataFrame()\n",
    "    x = df[columns]\n",
    "    vif[\"VIF Factor\"] = [\n",
    "        variance_inflation_factor(x.values, i) for i in range(x.shape[1])\n",
    "    ]\n",
    "    vif[\"features\"] = columns\n",
    "    print(vif)\n",
    "    plt.barh(columns, vif[\"VIF Factor\"])\n",
    "    plt.vlines([5], 0, len(columns), \"blue\", linestyles='dashed')\n",
    "    plt.vlines([10], 0, len(columns), \"red\", linestyles='dashed')\n",
    "    plt.title(\"VIF\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# 実行\n",
    "print_correlation(df_train, select_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06c78e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
